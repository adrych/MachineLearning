{
 "metadata": {
  "name": "",
  "signature": "sha256:ac7d2cfa339b3eb08d511a209141feec086f014b2a06c7435a3e8e8741306d99"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Wielowarstwowe sieci neuronowe\n",
      "## Uczenie za pomoc\u0105 gotowych pakiet\u00f3w\n",
      "\n",
      "B\u0119dziemy dzi\u015b korzysta\u0107 z zaawansowanego pakietu do sieci neuronowych \"Keras\". \n",
      "\n",
      "### Instalacja\n",
      "* Pod Windowsem powinno by\u0107 wszystko zainstalowane.\n",
      "* Pod Linuxem mo\u017cna zainstalowa\u0107 lokalnie:\n",
      "        pip install --user keras\n",
      "* Lub na w\u0142asnym komputerze:\n",
      "        sudo pip install keras\n",
      "* Mo\u017cliwe, \u017ce konieczne jest ponowne uruchomienie IPython, je\u015bli by\u0142 uruchomiony podczas instalacji.\n",
      "\n",
      "### Dokumentacja\n",
      "* Dosy\u0107 pe\u0142na i obszerna dokumentacja na: http://keras.io\n",
      "* Pomocne przyk\u0142ady na: https://github.com/fchollet/keras/tree/master/examples (zaawansowane)\n",
      "* Szczeg\u00f3lnie przyk\u0142ad: mnist_mlp.py\n",
      "* ***Uwaga:*** pierwsze uruchomienie zazwyczaj trwa jaki\u015b czas, poniewa\u017c pod spodem model kompiluje si\u0119 jako aplikacja w C++. \n",
      "\n",
      "### Zadania\n",
      "\n",
      "#### MNIST\n",
      "1. Uruchom przyk\u0142ad mnist_mlp.py, warto ew. zmieni\u0107 liczb\u0119 epok do 5 \n",
      "1. Przeanalizuj kod za pomoc\u0105 dokumentacji oraz innych \u017ar\u00f3de\u0142 w internecie i opisz w notebooku:\n",
      "    1. Do jakiej postaci autorzy przyk\u0142adu sprowadzaj\u0105 dane Y_train i Y_test?\n",
      "    1. Przedstaw wz\u00f3r matematyczny na funkcj\u0119 b\u0142\u0119du (pojawi\u0142a si\u0119\u00a0na wyk\u0142adzie)\n",
      "    1. Ile warstw ma przyk\u0142adowy model, jakie s\u0105\u00a0rozmiary macierzy odpowiednich wag. Czy mo\u017cna uzyska\u0107 dost\u0119p do tych wag?\n",
      "    1. Jakie funkcje aktywacji u\u017cyto? Podaj ich wzory, dla RELU stw\u00f3rz wykres.\n",
      "    1. Co to jest Dropout? Czemu s\u0142u\u017cy? Jakie znaczenie ma parametr?\n",
      "1. Zmodyfikuj model:\n",
      "    1. Usu\u0144 warstwy Dropout, jaki jest efekt?\n",
      "    1. Stw\u00f3rz model odpowiadaj\u0105cy 10-klasowej regresji logistycznej (om\u00f3wiony na wyk\u0142adzie): jaka jest jako\u015b\u0107?\n",
      "    1. Stw\u00f3rz 6-cio warstwowy model o rozmiarach warstw 2500, 2000, 1500, 1000, 500 oraz 10 bez Dropout, u\u017cyj wsz\u0119dzie funkcji aktywacji `tanh` z wyj\u0105tkiem ostatniej warstwy, gdzie nale\u017cy u\u017cy\u0107 `softmax`. Trenuj model przez 10 epok.\n",
      "    1. Dodaj warstwy Dropout, porownaj jako\u015b\u0107 po 10 epokach. \n",
      "    1. Zamiast RMSprop u\u017cyj algorytm Adagrad, por\u00f3wnaj jako\u015b\u0107. \n",
      "\n",
      "#### XOR\n",
      "1. Poka\u017c, \u017ce jednowarstowa sie\u0107 (z jednym neuronem z sigmoidaln\u0105\u00a0funkcj\u0105 aktywacji) nie potrafi nauczy\u0107\u00a0si\u0119\u00a0funkcji XOR ale za to AND i OR. Wykorzystaj funkcj\u0119 model.predict(...). Przyjmyj, \u017ce warto\u015bci &le;0.1 to 0 oraz warto\u015bci &ge;0.9 to 1. Jaka funkcja bl\u0119du wydaj\u0119\u00a0sie w\u0142asciwa?\n",
      "2. Poka\u017c, \u017ce dwuwarstowy perceptron potrafi nauczy\u0107 si\u0119 funkcji XOR. Wykorzystuj\u0105c model typu `Graph`, zbuduj nast\u0119puj\u0105c\u0105 sie\u0107:\n",
      "        x1 -> nh\n",
      "        x2 -> nh\n",
      "        x1 -> no\n",
      "        x2 -> no\n",
      "        nh -> no\n",
      "Gdzie `x1` i `x2` to wejscia, `nh` to neuron ukryty, `no` to neuron wyj\u015bciowy. Zwr\u00f3c uwag\u0119, \u017ce po\u0142\u0105czenia wychodz\u0105 poza warstwy. W\u0142a\u015bciwym trybem \u0142\u0105czenia wej\u015b\u0107 do neuronu wyj\u015bciowego to `merge_mode='concat'` (skleja wyj\u015bcia poprzednich warstw podanych w `inputs=[w1, w2]` w jeden ci\u0105g). \n",
      "3. **Uwaga**: Konieczna jest du\u017ca liczba epok, ok. 10000. Zbior trenuj\u0105cy to tylko 4 przyk\u0142ady, zatem to p\u00f3jdzie szybko. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "2A. Do postaci macierzy klas binarnych (z wektor\u00f3w)\n",
      "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
      "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
      "\n",
      "2B. Funkcja kosztu:\n",
      "$$J(\\Theta) = \\dfrac{1}{2m} \\sum_{i=1}^{m} (h_\\Theta(x^{(i)})- y^{(i)})^2 $$\n",
      "\n",
      "2C. Model ma 2 warstwy. \n",
      "\n",
      "2D. RELU i softmax.\n",
      "Softmax:\n",
      "$$ \\textrm{softmax}(k,x_1,\\dots,x_n) = \\dfrac{e^{x_k}}{\\sum_{i=i}^{n}e^{x_i}} $$\n",
      "\n",
      "Relu (Rectified Linear Unit):\n",
      "$$ \\textrm{RELU}(x) = \\ln{(1+e^{x})} $$\n",
      "Wykres poni\u017cej\n",
      "\n",
      "2E. Dropout to skr\u00f3t od \"droping out units\", stosuje si\u0119 go do redukcji overfittingu. W fazie treningu wszystkie jednostki aktywacji w warstwie dropout s\u0105 nieaktywne. Jednostki do warstwy dropout s\u0105 wybierane losowo, w zale\u017cno\u015bci od parametru p (jest to u\u0142amek ca\u0142ego zestawu treningowego, ilo\u015b\u0107 jednostek do warstwy dropout.\n",
      "\n",
      "3A. Accuracy si\u0119 obni\u017cy\u0142o, test score wzr\u00f3s\u0142."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#RELU wykres\n",
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "## initialize the axes\n",
      "fig = plt.figure()\n",
      "ax = fig.add_subplot(111)\n",
      "\n",
      "t = np.arange(-20,20)\n",
      "s = np.log(1+np.exp(t))\n",
      "\n",
      "line, = ax.plot(t, s, color='blue', lw=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEACAYAAACuzv3DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAOTc/wMeMXIcFtV2+gAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7fd078e891d0>"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "import numpy as np\n",
      "np.random.seed(1337)  # for reproducibility\n",
      "\n",
      "from keras.datasets import mnist\n",
      "from keras.models import Sequential\n",
      "from keras.layers.core import Dense, Dropout, Activation\n",
      "from keras.optimizers import SGD, Adam, RMSprop, Adagrad\n",
      "from keras.utils import np_utils"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using Theano backend.\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 3B Jako\u015b\u0107: ~0.2984 Accuracy: 0.9151\n",
      "batch_size = 128\n",
      "nb_classes = 10\n",
      "nb_epoch = 5\n",
      "\n",
      "# the data, shuffled and split between tran and test sets\n",
      "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
      "\n",
      "X_train = X_train.reshape(60000, 784)\n",
      "X_test = X_test.reshape(10000, 784)\n",
      "X_train = X_train.astype('float32')\n",
      "X_test = X_test.astype('float32')\n",
      "X_train /= 255\n",
      "X_test /= 255\n",
      "print(X_train.shape[0], 'train samples')\n",
      "print(X_test.shape[0], 'test samples')\n",
      "\n",
      "# convert class vectors to binary class matrices\n",
      "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
      "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
      "\n",
      "model = Sequential()\n",
      "model.add(Dense(512, input_shape=(784,)))\n",
      "model.add(Activation('tanh'))\n",
      "#model.add(Dropout(0.2))\n",
      "model.add(Dense(512))\n",
      "model.add(Activation('tanh'))\n",
      "#model.add(Dropout(0.2))\n",
      "model.add(Dense(10))\n",
      "model.add(Activation('softmax'))\n",
      "\n",
      "rms = RMSprop()\n",
      "sgd = SGD()\n",
      "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
      "\n",
      "model.fit(X_train, Y_train,\n",
      "          batch_size=batch_size, nb_epoch=nb_epoch,\n",
      "          show_accuracy=True, verbose=2,\n",
      "          validation_data=(X_test, Y_test))\n",
      "score = model.evaluate(X_test, Y_test,\n",
      "                       show_accuracy=True, verbose=0)\n",
      "print('Test score:', score[0])\n",
      "print('Test accuracy:', score[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "60000 train samples\n",
        "10000 test samples\n",
        "Train on 60000 samples, validate on 10000 samples"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 1/5\n",
        "15s - loss: 0.7968 - acc: 0.8109 - val_loss: 0.4492 - val_acc: 0.8841\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 2/5\n",
        "14s - loss: 0.4181 - acc: 0.8879 - val_loss: 0.3621 - val_acc: 0.8984\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 3/5\n",
        "15s - loss: 0.3622 - acc: 0.8990 - val_loss: 0.3283 - val_acc: 0.9077\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 4/5\n",
        "14s - loss: 0.3350 - acc: 0.9055 - val_loss: 0.3110 - val_acc: 0.9120\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 5/5\n",
        "14s - loss: 0.3180 - acc: 0.9096 - val_loss: 0.2984 - val_acc: 0.9151\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Test score: 0.298420210195\n",
        "Test accuracy: 0.9151\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# 3C 6 class model 10 epochs\n",
      "#Wyniki:\n",
      "# Test score: 0.950818452835\n",
      "# Test accuracy: 0.783\n",
      "\n",
      "batch_size = 128\n",
      "nb_classes = 10\n",
      "nb_epoch = 10\n",
      "\n",
      "# the data, shuffled and split between tran and test sets\n",
      "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
      "\n",
      "X_train = X_train.reshape(60000, 784)\n",
      "X_test = X_test.reshape(10000, 784)\n",
      "#zmniejszona liczba danych bo m\u00f3j komputer nie wyrabia\n",
      "X_train = X_train[:10000,:]\n",
      "X_test = X_test[:1000,:]\n",
      "X_train = X_train.astype('float32')\n",
      "X_test = X_test.astype('float32')\n",
      "X_train /= 255\n",
      "X_test /= 255\n",
      "print(X_train.shape[0], 'train samples')\n",
      "print(X_test.shape[0], 'test samples')\n",
      "\n",
      "# convert class vectors to binary class matrices\n",
      "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
      "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
      "\n",
      "model = Sequential()\n",
      "model.add(Dense(2500, input_shape=(784,)))\n",
      "model.add(Activation('tanh'))\n",
      "#model.add(Dropout(0.2))\n",
      "model.add(Dense(2000))\n",
      "model.add(Activation('tanh'))\n",
      "#model.add(Dropout(0.2))\n",
      "model.add(Dense(1500))\n",
      "model.add(Activation('tanh'))\n",
      "model.add(Dense(1000))\n",
      "model.add(Activation('tanh'))\n",
      "model.add(Dense(500))\n",
      "model.add(Activation('tanh'))\n",
      "model.add(Dense(10))\n",
      "model.add(Activation('softmax'))\n",
      "\n",
      "rms = RMSprop()\n",
      "sgd = SGD()\n",
      "model.compile(loss='categorical_crossentropy', optimizer=rms)\n",
      "\n",
      "model.fit(X_train, Y_train,\n",
      "          batch_size=batch_size, nb_epoch=nb_epoch,\n",
      "          show_accuracy=True, verbose=2,\n",
      "          validation_data=(X_test, Y_test))\n",
      "score = model.evaluate(X_test, Y_test,\n",
      "                       show_accuracy=True, verbose=0)\n",
      "print('Test score:', score[0])\n",
      "print('Test accuracy:', score[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10000 train samples\n",
        "1000 test samples\n",
        "Train on 10000 samples, validate on 1000 samples"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Epoch 1/10\n",
        "63s - loss: 2.0586 - acc: 0.4350 - val_loss: 2.1715 - val_acc: 0.4540\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 2/10\n",
        "63s - loss: 0.5859 - acc: 0.8228 - val_loss: 0.9704 - val_acc: 0.7530\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 3/10\n",
        "64s - loss: 0.3799 - acc: 0.8898 - val_loss: 0.7392 - val_acc: 0.7680\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 4/10\n",
        "62s - loss: 0.2793 - acc: 0.9163 - val_loss: 0.7742 - val_acc: 0.7960\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 5/10\n",
        "64s - loss: 0.2312 - acc: 0.9271 - val_loss: 0.3462 - val_acc: 0.8850\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 6/10\n",
        "63s - loss: 0.1751 - acc: 0.9450 - val_loss: 1.8024 - val_acc: 0.6690\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 7/10\n",
        "63s - loss: 0.1960 - acc: 0.9448 - val_loss: 0.3371 - val_acc: 0.9050\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 8/10\n",
        "64s - loss: 0.1288 - acc: 0.9603 - val_loss: 1.2225 - val_acc: 0.7460\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 9/10\n",
        "65s - loss: 0.1341 - acc: 0.9595 - val_loss: 1.5531 - val_acc: 0.6910\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 10/10\n",
        "63s - loss: 0.1174 - acc: 0.9669 - val_loss: 0.9508 - val_acc: 0.7830\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Test score: 0.950818452835\n",
        "Test accuracy: 0.783\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#3D dropout added\n",
      "#Wyniki\n",
      "# Test score: 0.482511591434\n",
      "# Test accuracy: 0.888\n",
      "\n",
      "model = Sequential()\n",
      "model.add(Dense(2500, input_shape=(784,)))\n",
      "model.add(Activation('tanh'))\n",
      "model.add(Dropout(0.2))\n",
      "model.add(Dense(2000))\n",
      "model.add(Activation('tanh'))\n",
      "model.add(Dropout(0.2))\n",
      "model.add(Dense(1500))\n",
      "model.add(Activation('tanh'))\n",
      "model.add(Dropout(0.2))\n",
      "model.add(Dense(1000))\n",
      "model.add(Activation('tanh'))\n",
      "model.add(Dropout(0.2))\n",
      "model.add(Dense(500))\n",
      "model.add(Activation('tanh'))\n",
      "model.add(Dropout(0.2))\n",
      "model.add(Dense(10))\n",
      "model.add(Activation('softmax'))\n",
      "\n",
      "sgd = SGD()\n",
      "model.compile(loss='categorical_crossentropy', optimizer=rms)\n",
      "\n",
      "model.fit(X_train, Y_train,\n",
      "          batch_size=batch_size, nb_epoch=nb_epoch,\n",
      "          show_accuracy=True, verbose=2,\n",
      "          validation_data=(X_test, Y_test))\n",
      "score = model.evaluate(X_test, Y_test,\n",
      "                       show_accuracy=True, verbose=0)\n",
      "print('Test score:', score[0])\n",
      "print('Test accuracy:', score[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train on 10000 samples, validate on 1000 samples\n",
        "Epoch 1/10\n",
        "64s - loss: 1.6263 - acc: 0.6101 - val_loss: 2.0947 - val_acc: 0.6010\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 2/10\n",
        "63s - loss: 0.4440 - acc: 0.8694 - val_loss: 0.4444 - val_acc: 0.8720\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 3/10\n",
        "63s - loss: 0.2907 - acc: 0.9131 - val_loss: 1.1261 - val_acc: 0.7760\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 4/10\n",
        "63s - loss: 0.2550 - acc: 0.9252 - val_loss: 0.5195 - val_acc: 0.8230\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 5/10\n",
        "64s - loss: 0.1872 - acc: 0.9445 - val_loss: 0.2160 - val_acc: 0.9320\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 6/10\n",
        "63s - loss: 0.1409 - acc: 0.9553 - val_loss: 0.2548 - val_acc: 0.9320\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 7/10\n",
        "63s - loss: 0.1257 - acc: 0.9593 - val_loss: 0.8626 - val_acc: 0.7910\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 8/10\n",
        "63s - loss: 0.1270 - acc: 0.9595 - val_loss: 0.2623 - val_acc: 0.9230\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 9/10\n",
        "63s - loss: 0.0866 - acc: 0.9707 - val_loss: 0.2371 - val_acc: 0.9360\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 10/10\n",
        "63s - loss: 0.0850 - acc: 0.9719 - val_loss: 0.4825 - val_acc: 0.8880\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Test score: 0.482511591434\n",
        "Test accuracy: 0.888\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#3E adagrad\n",
      "#Wyniki:\n",
      "# Test score: 0.411591641665\n",
      "# Test accuracy: 0.886\n",
      "\n",
      "model = Sequential()\n",
      "model.add(Dense(2500, input_shape=(784,)))\n",
      "model.add(Activation('tanh'))\n",
      "model.add(Dropout(0.2))\n",
      "model.add(Dense(2000))\n",
      "model.add(Activation('tanh'))\n",
      "model.add(Dropout(0.2))\n",
      "model.add(Dense(1500))\n",
      "model.add(Activation('tanh'))\n",
      "model.add(Dropout(0.2))\n",
      "model.add(Dense(1000))\n",
      "model.add(Activation('tanh'))\n",
      "model.add(Dropout(0.2))\n",
      "model.add(Dense(500))\n",
      "model.add(Activation('tanh'))\n",
      "model.add(Dropout(0.2))\n",
      "model.add(Dense(10))\n",
      "model.add(Activation('softmax'))\n",
      "\n",
      "adagrad = Adagrad()\n",
      "model.compile(loss='categorical_crossentropy', optimizer=adagrad)\n",
      "\n",
      "model.fit(X_train, Y_train,\n",
      "          batch_size=batch_size, nb_epoch=nb_epoch,\n",
      "          show_accuracy=True, verbose=2,\n",
      "          validation_data=(X_test, Y_test))\n",
      "score = model.evaluate(X_test, Y_test,\n",
      "                       show_accuracy=True, verbose=0)\n",
      "print('Test score:', score[0])\n",
      "print('Test accuracy:', score[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Train on 10000 samples, validate on 1000 samples\n",
        "Epoch 1/10\n",
        "65s - loss: 4.0010 - acc: 0.1027 - val_loss: 3.6466 - val_acc: 0.0870\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 2/10\n",
        "66s - loss: 3.7442 - acc: 0.1046 - val_loss: 3.5849 - val_acc: 0.0870\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 3/10\n",
        "64s - loss: 3.7244 - acc: 0.1102 - val_loss: 3.5226 - val_acc: 0.0990\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 4/10\n",
        "73s - loss: 3.4946 - acc: 0.1723 - val_loss: 3.2388 - val_acc: 0.1940\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 5/10\n",
        "69s - loss: 3.2540 - acc: 0.2158 - val_loss: 3.5567 - val_acc: 0.2010\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 6/10\n",
        "64s - loss: 2.2995 - acc: 0.3821 - val_loss: 1.4549 - val_acc: 0.4590\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 7/10\n",
        "66s - loss: 1.1181 - acc: 0.5773 - val_loss: 1.3026 - val_acc: 0.5890\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 8/10\n",
        "65s - loss: 0.7325 - acc: 0.7633 - val_loss: 1.3236 - val_acc: 0.5950\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 9/10\n",
        "67s - loss: 0.5283 - acc: 0.8512 - val_loss: 2.0892 - val_acc: 0.5580\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Epoch 10/10\n",
        "67s - loss: 0.4456 - acc: 0.8812 - val_loss: 0.4116 - val_acc: 0.8860\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Test score: 0.411591641665\n",
        "Test accuracy: 0.886\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#XOR\n",
      "import numpy as np\n",
      "\n",
      "X_train = np.array([[0.0,0.0],[0.0,1.0],[1.0,0.0],[1.0,1.0]])\n",
      "y_train = np.array([[0.0],[1.0],[1.0],[0.0]])\n",
      "\n",
      "X_test = np.array([[0.0,1.0],[1.0,1.0],[0.0,0.0],[1.0,0.0]])\n",
      "y_test = np.array([[1.0],[0.0],[0.0],[1.0]])\n",
      "\n",
      "batch_size = 128\n",
      "nb_classes = 2\n",
      "nb_epoch = 10000\n",
      "\n",
      "\n",
      "# convert class vectors to binary class matrices\n",
      "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
      "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
      "\n",
      "model = Sequential()\n",
      "model.add(Dense(2, input_shape=(2,)))\n",
      "model.add(Activation('sigmoid'))\n",
      "\n",
      "rms = RMSprop()\n",
      "sgd = SGD()\n",
      "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
      "\n",
      "model.fit(X_train, Y_train,\n",
      "          batch_size=batch_size, nb_epoch=nb_epoch,\n",
      "          show_accuracy=True, verbose=0,\n",
      "          validation_data=(X_test, Y_test))\n",
      "score = model.evaluate(X_test, Y_test,\n",
      "                       show_accuracy=True, verbose=0)\n",
      "print('Test score:', score[0])\n",
      "print('Test accuracy:', score[1])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Test score: 0.542351067066\n",
        "Test accuracy: 0.5\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Test accuracy wynosi 0.5 czyli tylko dwie z liczb zosta\u0142y poprawnie sklasyfikowane"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#AND\n",
      "\n",
      "X_train = np.array([[0.0,0.0],[0.0,1.0],[1.0,0.0],[1.0,1.0]])\n",
      "y_train = np.array([[0.0],[0.0],[0.0],[1.0]])\n",
      "\n",
      "X_test = np.array([[0.0,1.0],[1.0,1.0],[0.0,0.0],[1.0,0.0]])\n",
      "y_test = np.array([[0.0],[1.0],[0.0],[0.0]])\n",
      "\n",
      "batch_size = 128\n",
      "nb_classes = 2\n",
      "nb_epoch = 10000\n",
      "\n",
      "\n",
      "# convert class vectors to binary class matrices\n",
      "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
      "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
      "\n",
      "model = Sequential()\n",
      "model.add(Dense(2, input_shape=(2,)))\n",
      "model.add(Activation('sigmoid'))\n",
      "\n",
      "rms = RMSprop()\n",
      "sgd = SGD()\n",
      "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
      "\n",
      "model.fit(X_train, Y_train,\n",
      "          batch_size=batch_size, nb_epoch=nb_epoch,\n",
      "          show_accuracy=True, verbose=0,\n",
      "          validation_data=(X_test, Y_test))\n",
      "score = model.evaluate(X_test, Y_test,\n",
      "                       show_accuracy=True, verbose=0)\n",
      "print('Test score:', score[0])\n",
      "print('Test accuracy:', score[1])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Test score: 0.103746116161\n",
        "Test accuracy: 1.0\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Test accuracy wysz\u0142o 1.0, czyli si\u0119 uda\u0142o"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#OR\n",
      "\n",
      "X_train = np.array([[0.0,0.0],[0.0,1.0],[1.0,0.0],[1.0,1.0]])\n",
      "y_train = np.array([[0.0],[1.0],[1.0],[1.0]])\n",
      "\n",
      "X_test = np.array([[0.0,1.0],[1.0,1.0],[0.0,0.0],[1.0,0.0]])\n",
      "y_test = np.array([[1.0],[1.0],[0.0],[1.0]])\n",
      "\n",
      "batch_size = 128\n",
      "nb_classes = 2\n",
      "nb_epoch = 10000\n",
      "\n",
      "\n",
      "# convert class vectors to binary class matrices\n",
      "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
      "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
      "\n",
      "model = Sequential()\n",
      "model.add(Dense(2, input_shape=(2,)))\n",
      "model.add(Activation('sigmoid'))\n",
      "\n",
      "rms = RMSprop()\n",
      "sgd = SGD()\n",
      "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
      "\n",
      "model.fit(X_train, Y_train,\n",
      "          batch_size=batch_size, nb_epoch=nb_epoch,\n",
      "          show_accuracy=True, verbose=0,\n",
      "          validation_data=(X_test, Y_test))\n",
      "score = model.evaluate(X_test, Y_test,\n",
      "                       show_accuracy=True, verbose=0)\n",
      "print('Test score:', score[0])\n",
      "print('Test accuracy:', score[1])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Test score: 0.0731879994273\n",
        "Test accuracy: 1.0\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Test accuracy wynosi 1.0, czyli ok"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#XOR\n",
      "from keras.models import Graph\n",
      "import numpy as np\n",
      "\n",
      "X_train = np.array([[0.0,0.0],[0.0,1.0],[1.0,0.0],[1.0,1.0]])\n",
      "y_train = np.array([[0.0],[1.0],[1.0],[0.0]])\n",
      "\n",
      "X_test = np.array([[0.0,1.0],[1.0,1.0],[0.0,0.0],[1.0,0.0]])\n",
      "y_test = np.array([[1.0],[0.0],[0.0],[1.0]])\n",
      "\n",
      "batch_size = 128\n",
      "nb_classes = 2\n",
      "nb_epoch = 10000\n",
      "\n",
      "\n",
      "# convert class vectors to binary class matrices\n",
      "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
      "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
      "\n",
      "\n",
      "graph = Graph()\n",
      "graph.add_input(name='input', input_shape=(2,))\n",
      "graph.add_node(Dense(input_dim = 2, output_dim = 2, activation = 'sigmoid'), name='nh', input ='input')\n",
      "graph.add_node(Dense(input_dim = 3, output_dim = 2), name='x1x2', inputs=['input', 'nh'])\n",
      "graph.add_output(name='output', input='x1x2', merge_mode='concat')\n",
      "\n",
      "rms = RMSprop()\n",
      "graph.compile(optimizer=rms, loss={'output':'mse'})\n",
      "history = graph.fit({'input':X_train, 'output':Y_train}, batch_size=batch_size, nb_epoch=nb_epoch,\n",
      "          verbose=0)\n",
      "\n",
      "score = graph.evaluate({'input':X_test, 'output':Y_test})\n",
      "print (score)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3.9893993744e-06\n"
       ]
      }
     ],
     "prompt_number": 141
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}