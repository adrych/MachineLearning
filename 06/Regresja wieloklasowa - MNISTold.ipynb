{
 "metadata": {
  "name": "",
  "signature": "sha256:5961859546367e7e6d8aaa70ba3a57771449353e9d2c93fd384fa46829a196c0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Zadania"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Zadania dotycz\u0105\u00a0rozpoznawania obrazu, b\u0119dziemy klasyfikowa\u0107\u00a0obrazki r\u0119cznie zapisanych liczb. Zestaw danych, na kt\u00f3rym b\u0119dziemy pracowa\u0107, to s\u0142ynny MNIST (https://en.wikipedia.org/wiki/MNIST_database)\n",
      "\n",
      "Obrazki te wygl\u0105daj\u0105 np.\u00a0tak: <img src=\"http://pavel.surmenok.com/wp-content/uploads/2014/07/mnistdigits.gif\"/>. W bazie MNIST jest ich ok. 70.000 oznaczonych odpowiedznimi liczbami. Zadanie polega na identyfikacji liczby przedstawionej na jednym obrazku.\n",
      "\n",
      "## Przygotowania\n",
      "\n",
      "1. Prosz\u0119 \u015bci\u0105gna\u0107\u00a0sobie cztery pliki `*-images-idx3-ubyte.gz` ze strony http://yann.lecun.com/exdb/mnist/ i rozpakowa\u0107 (!) w tym samym katalogu, w kt\u00f3rym znajduje si\u0119 notebook. Na tej stronie przy okazji s\u0105\u00a0podane wyniki dla niekt\u00f3rych metod. Z regresj\u0105\u00a0logistyczn\u0105 (`linear classifier`) powinni\u015bmy o\u015biagn\u0105c poprawno\u015b\u0107\u00a0ok. 90%, czyli \"error rate\" ok. 10% dla ca\u0142o\u015bci danych.\n",
      "2. Za pomoc\u0105 podanych funkcji `read` i `show` (znalaz\u0142em w internecie, nie trzeba si\u0119\u00a0przejmowa\u0107 za bardzo ich tre\u015bci\u0105) wy\u015bwietli\u0107\u00a0prosz\u0119\u00a0w postaci tablicy `numpy` oraz w posta\u0107i obrazka pierwsze dziesie\u0107 liczb. \n",
      "3. Stworzy\u0107 macierz dla danych trenuj\u0105cych, na pocz\u0105tek dla pierwszych 1000 (`maxItems` w funkcji `toMatrix`, podanie `maxItems=60000` wczyta wszystkie dane). To samo dla danych testowych. \n",
      "4. Zastanowi\u0107 si\u0119: ile cech ma ka\u017cdy obrazek, czym s\u0105 te cechy?\n",
      "\n",
      "## Regresja logistyczna\n",
      "\n",
      "5. Wykorzystuj\u0105c materia\u0142y z ostatniego wyk\u0142adu, wytrenowa\u0107 model regresji logistycznej binarnej dla samych rozpoznaj\u0105cy zera na danych trenuj\u0105cych. Jak\u0105\u00a0osi\u0105gniemy poprawno\u015b\u0107 (accuracy)? (Uwaga, w algorytmie GD wybra\u0107 na pocz\u0105tku ma\u0142a liczb\u0119 krok\u00f3w, np. 100, i powoli zwi\u0119ksza\u0107).\n",
      "6. Na podstawie ostatnie wyk\u0142adu, zbuduj model regresji logistycznej dla wszystkich liczb. Jak\u0105\u00a0osi\u0105gamy poprawno\u015b\u0107\u00a0dla wszystkich klas?\n",
      "7. Spr\u00f3buj zwi\u0119kszy\u0107 liczb\u0119 danych z 1000 na 10000 itd. Co si\u0119\u00a0zaczyna dzia\u0107 z algorytmem GD?\n",
      "8. Zaimplementuj algorytm Batch-SGD (Batch Stochastic Gradient Descent). Prowadz\u0105cy wyja\u015bni na \u0107wiczeniach, na czym polega r\u00f3\u017cnica do naszego zwyk\u0142ego GD. \n",
      "9. Za pomoc\u0105\u00a0Batch-SGD zbuduj model dla ca\u0142osci danych trenuj\u0105cych. Jaki osi\u0105gamy wynik accuracy bawi\u0105c si\u0119 parametrami `alpha`, `maxSteps` i `batchSize`?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import struct\n",
      "import numpy as np\n",
      "\n",
      "%matplotlib inline\n",
      "\n",
      "def read(dataset = \"training\", path = \".\"):\n",
      "    \"\"\"\n",
      "    Python function for importing the MNIST data set.  It returns an iterator\n",
      "    of 2-tuples with the first element being the label and the second element\n",
      "    being a numpy.uint8 2D array of pixel data for the given image.\n",
      "    \"\"\"\n",
      "\n",
      "    if dataset is \"training\":\n",
      "        fname_img = os.path.join(path, 'train-images.idx3-ubyte')\n",
      "        fname_lbl = os.path.join(path, 'train-labels.idx1-ubyte')\n",
      "    elif dataset is \"testing\":\n",
      "        fname_img = os.path.join(path, 't10k-images.idx3-ubyte')\n",
      "        fname_lbl = os.path.join(path, 't10k-labels.idx1-ubyte')\n",
      "    else:\n",
      "        raise ValueError, \"dataset must be 'testing' or 'training'\"\n",
      "\n",
      "    # Load everything in some numpy arrays\n",
      "    with open(fname_lbl, 'rb') as flbl:\n",
      "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
      "        lbl = np.fromfile(flbl, dtype=np.int8)\n",
      "\n",
      "    with open(fname_img, 'rb') as fimg:\n",
      "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
      "        img = np.fromfile(fimg, dtype=np.uint8).reshape(len(lbl), rows, cols)\n",
      "\n",
      "    get_img = lambda idx: (lbl[idx], img[idx])\n",
      "\n",
      "    # Create an iterator which returns each image in turn\n",
      "    for i in xrange(len(lbl)):\n",
      "        yield get_img(i)\n",
      "\n",
      "def show(image):\n",
      "    \"\"\"\n",
      "    Render a given numpy.uint8 2D array of pixel data.\n",
      "    \"\"\"\n",
      "    from matplotlib import pyplot\n",
      "    import matplotlib as mpl\n",
      "    fig = pyplot.figure()\n",
      "    ax = fig.add_subplot(1,1,1)\n",
      "    imgplot = ax.imshow(image, cmap=mpl.cm.Greys)\n",
      "    imgplot.set_interpolation('nearest')\n",
      "    ax.xaxis.set_ticks_position('top')\n",
      "    ax.yaxis.set_ticks_position('left')\n",
      "    pyplot.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def toMatrix(data, maxItems=1000):\n",
      "    datalist = [t for t in data]\n",
      "    m = maxItems\n",
      "    n = 28 * 28 + 1\n",
      "    X = np.matrix(np.zeros(m * n)).reshape(m, n)\n",
      "    Y = np.matrix(np.zeros(m)).reshape(m, 1)\n",
      "    for i, (label, image) in enumerate(datalist[:m]):\n",
      "        X[i, 0] = 1 # bias term\n",
      "        X[i, 1:] = image.reshape(28*28,)\n",
      "        Y[i] = label\n",
      "    return X, Y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_train = list(read())\n",
      "data_test = list(read(\"testing\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#for i in range(0,10):\n",
      "#    show(data_train[i][1])\n",
      "    \n",
      "data_matrix = toMatrix(data_train)\n",
      "data_matrix = toMatrix(data_test)\n",
      "#for i in range(0,10):\n",
      "#    print data_matrix[0][i]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def h(theta, X):\n",
      "    return 1.0/(1.0 + np.exp(-X*theta))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#zad1.3\n",
      "train1000 = toMatrix(data_train, 1000)\n",
      "test1000= toMatrix(data_test, 1000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#regresja logistyczna\n",
      "#zad1\n",
      "\n",
      "Xtrain = train1000[0][:]\n",
      "Ytrain = train1000[1][:]\n",
      "\n",
      "#YTrainBi[0 if YTrain == 0 else 1]\n",
      "\n",
      "Xtest = test1000[0][:]\n",
      "Ytest = test1000[1][:]\n",
      "\n",
      "\n",
      "m, n = Xtrain.shape\n",
      "\n",
      "for i in range(0, m):\n",
      "    if Ytrain[i] != 0:\n",
      "        Ytrain[i] = 1\n",
      "        \n",
      "for i in range(0, m):\n",
      "    if Ytest[i] != 0:\n",
      "        Ytest[i] = 1\n",
      "        \n",
      "\n",
      "Xtrain = np.matrix(np.concatenate((np.ones((m, 1)), Xtrain), axis=1)).reshape(m,n+1)\n",
      "Xtest = np.matrix(np.concatenate((np.ones((m, 1)), Xtest), axis=1)).reshape(m,n+1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def logistic(x):\n",
      "    return 1.0/(1.0 + np.exp(-x))\n",
      "\n",
      "def h(theta, X):\n",
      "    return 1.0/(1.0 + np.exp(-X*theta))\n",
      "\n",
      "thetaTemp = np.zeros(n+1).reshape(n+1,1)\n",
      "#h(thetaTemp, Xtrain[0:10])\n",
      "\n",
      "\n",
      "def J(h,theta,X,y):\n",
      "    m = len(y)\n",
      "    s1 = np.multiply(y, np.log(h(theta,X)))\n",
      "    s2 = np.multiply((1 - y), np.log(1 - h(theta,X)))\n",
      "    return -np.sum(s1 + s2, axis=0)/m\n",
      "\n",
      "print(J(h, thetaTemp, Xtrain, Ytrain))\n",
      "\n",
      "def dJ(h,theta,X,y):\n",
      "    return 1.0/len(y)*(X.T*(h(theta,X)-y)) \n",
      "\n",
      "\n",
      "#print(dJ(h, thetaTemp, Xtrain, Ytrain))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.69314718]]\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def GD(h, fJ, fdJ, theta, X, y, \n",
      "         alpha=0.01, eps=10**-3, maxSteps=10000):\n",
      "    errorCurr = fJ(h, theta, X, y)\n",
      "    errors = [[errorCurr, theta]]\n",
      "    while True:\n",
      "        theta = theta - alpha * fdJ(h, theta, X, y)\n",
      "        errorCurr, errorPrev = fJ(h, theta, X, y), errorCurr\n",
      "        if abs(errorPrev - errorCurr) <= eps:\n",
      "            break\n",
      "        if len(errors) > maxSteps:\n",
      "            break\n",
      "        errors.append([errorCurr, theta]) \n",
      "    return theta, errors\n",
      "\n",
      "thetaBest, errors = GD(h, J, dJ, thetaTemp, Xtrain, Ytrain, \n",
      "                       alpha=0.0001, eps=10**-7, maxSteps=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:14: RuntimeWarning: divide by zero encountered in log\n",
        "-c:14: RuntimeWarning: invalid value encountered in multiply\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def classifyBi(X):\n",
      "    prob = h(thetaBest, X).item()\n",
      "    return (1, prob) if prob > 0.5 else (0, prob)\n",
      "\n",
      "acc = 0.0\n",
      "for i, rest in enumerate(Ytest):\n",
      "    cls, prob = classifyBi(Xtest[i])\n",
      "    #print int(Ytest[i].item()), \"<=>\", cls, \"-- prob:\", round(prob, 4)\n",
      "    acc += cls == Ytest[i].item()\n",
      "print \"Accuracy:\", acc/len(Xtest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy: 0.984\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_train = list(read())\n",
      "data_test = list(read(\"testing\"))\n",
      "\n",
      "train1000 = toMatrix(data_train, 1000)\n",
      "test1000= toMatrix(data_test, 1000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#zad2 & 4 & 5\n",
      "#zad 3 na koncu\n",
      "\n",
      "Xtrain = train1000[0][:]\n",
      "Xtest = test1000[0][:]\n",
      "\n",
      "m, n = Xtrain.shape\n",
      "\n",
      "Xtrain = np.matrix(np.concatenate((np.ones((m, 1)), Xtrain), axis=1)).reshape(m,n+1)\n",
      "Xtest = np.matrix(np.concatenate((np.ones((m, 1)), Xtest), axis=1)).reshape(m,n+1)\n",
      "\n",
      "YtrainB = train1000[1][:]\n",
      "YtestB = test1000[1][:]\n",
      "\n",
      "YtrainAll = np.zeros((m,10))\n",
      "YtestAll = np.zeros((m,10))\n",
      "\n",
      "\n",
      "\n",
      "for i in range(0, m):\n",
      "    for j in range(0,10):\n",
      "        if YtrainB[i] == j:\n",
      "            YtrainAll[i,j] = 1\n",
      "        if YtestB[i] == j:\n",
      "            YtestAll[i,j] = 1\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def softmax(X):\n",
      "    return np.exp(X)/np.sum(np.exp(X))\n",
      "\n",
      "def softmax(X):\n",
      "    X128 = X.astype(np.float128)\n",
      "    r = np.exp(X128)/np.sum(np.exp(X128))\n",
      "    return r\n",
      "\n",
      "def mbSGD(h, fJ, fdJ, theta, X, y, \n",
      "         alpha=0.01, maxSteps=10000, batchSize = 10):\n",
      "    #errorCurr = fJ(h, theta, X, y)\n",
      "    i = 0\n",
      "    b = batchSize\n",
      "    m = X.shape[0]\n",
      "    while i < maxSteps:\n",
      "        start = (i*b) % m\n",
      "        end   = ((i+1)*b) % m\n",
      "        if(end <= start):\n",
      "            end = m\n",
      "        Xbatch = X[start:end]\n",
      "        Ybatch = y[start:end].reshape(batchSize,1)\n",
      "\n",
      "\n",
      "        theta = theta - alpha * fdJ(h, theta, Xbatch, Ybatch)\n",
      "\n",
      "        i += 1\n",
      "    return theta, []\n",
      "\n",
      "def trainMaxEnt(X, Y):\n",
      "    n = X.shape[1]\n",
      "    thetas = []\n",
      "    for c in range(Y.shape[1]):\n",
      "        YBi = Y[:,c]\n",
      "        theta = np.matrix(np.random.random(n)).reshape(n,1)\n",
      "        #print theta.shape\n",
      "        thetaBest, errors = mbSGD(h, J, dJ, theta, X, YBi, \n",
      "                       alpha=0.0001, maxSteps=100000, batchSize = 100)\n",
      "        thetas.append(thetaBest)\n",
      "    return thetas\n",
      "\n",
      "thetas = trainMaxEnt(Xtrain, YtrainAll)\n",
      "Xtrain.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "(1000, 786)"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def classify(thetas, X):\n",
      "    regs = np.array([(X*theta).item() for theta in thetas])\n",
      "    probs = softmax(regs)\n",
      "    return np.argmax(probs), probs\n",
      "\n",
      "#print(YtestAll[:10])\n",
      "YtestCls = YtestAll * np.matrix((range(0,10))).T\n",
      "#print(YtestCls[:10])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "YtestBi = YtestAll[:,1]\n",
      "\n",
      "def classify(thetas, X):\n",
      "    regs = np.array([(X*theta).item() for theta in thetas])\n",
      "    probs = softmax(regs)\n",
      "    return np.argmax(probs), probs\n",
      "\n",
      "#print(YtestAll[:10])\n",
      "YTestCls = YtestAll * np.matrix((range(0,10))).T\n",
      "#print(YTestCls[:10])\n",
      "\n",
      "acc = 0.0\n",
      "for i in range(len(YTestCls)):\n",
      "    cls, probs = classify(thetas, Xtest[i])\n",
      "    correct = int(YTestCls[i].item())\n",
      "    #print correct, \"<=>\", cls, \" - \", correct == cls, np.round(probs, 4).tolist()\n",
      "    \n",
      "    acc += correct == cls\n",
      "print \"Accuracy =\", acc/float(len(Xtest))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy = 0.748\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Zad 3 - im wi\u0119cej danych trenuj\u0105cych tym wy\u017csza liczba dobrze rozpoznanych cyfr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Zad 5, im wi\u0119ksza liczba krok\u00f3w i mniejsza alpha, tym lepszy wynik. \n",
      "#Znaczna zmiana (zwi\u0119kszenie) batchSize r\u00f3wnie\u017c wp\u0142ywa na popraw\u0119 wyniku"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}